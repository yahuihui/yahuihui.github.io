{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"https://www.yahuihu.info"},"pages":[],"posts":[{"title":"harbor","slug":"harbor","date":"2018-04-03T09:34:00.000Z","updated":"2018-04-03T14:18:39.453Z","comments":true,"path":"2018/04/03/harbor/","link":"","permalink":"https://www.yahuihu.info/2018/04/03/harbor/","excerpt":"","text":"什么是 Harbor？Harbor是VMware公司開源的企業級DockerRegistry項目Harbor是一個用於存儲和分發的Docker鏡像的企業級Registry服務器Harbor提供更好的性能和安全性。使註冊表更接近構建和運行環境可提高圖像傳輸效率。Harbor與現有的企業LDAP / AD集成，用於用戶驗證和管理。 Harbor建置教學 環境準備Ubuntu 16.04 LTSPython 2.7 ↑Docker 1.10 ↑Docker-compose 1.6.0 ↑Docker Compose依靠Docker Engine進行任何有意義的工作。ex：Compose使用Docker標籤來追踪容器 安裝作業確認VM版本 Check Version執行apt-get update 和apt-get upgrade安裝python與驗證python版本安裝docker驗證docker版本安裝Docker Compose驗證Docker Compose","categories":[],"tags":[]},{"title":"filebeat","slug":"ELK_filebeat","date":"2018-03-28T09:14:34.000Z","updated":"2018-04-02T09:24:28.113Z","comments":true,"path":"2018/03/28/ELK_filebeat/","link":"","permalink":"https://www.yahuihu.info/2018/03/28/ELK_filebeat/","excerpt":"","text":"ELK 簡介ELK 是 Elasticsearch、Logstash 和 Kibana 三種軟體產品的首字母縮寫，這三者都是開源軟體。 Elasticsearch︰分散式搜索和分析引擎。具有高可伸縮、高可靠和易管理等特點。能對大容量的資料進行接近實時的存儲、搜索和分析操作。 Logstash︰資料收集引擎。從各種資料源搜集資料，並對資料進行過濾、分析、豐富、統一格式等操作，然後存儲到用戶指定的位置。 Kibana︰資料分析和可視化平台。通常與 Elasticsearch 配合使用，對其中資料進行搜索、分析和以統計圖表的方式展示。 Filebeat︰ELK 協議棧的新成員，一個輕量級開源日志檔案資料搜集器，基于 Logstash-Forwarder 源代碼開發。在需要采集日志資料的 server 上安裝 Filebeat，並指定日志目錄或日志檔案後，Filebeat 就能讀取資料，迅速傳送到 Logstash 進行解析，亦或直接傳送到Elasticsearch 進行集中式存儲和分析。 最簡單架構只有一個 Logstash、Elasticsearch 和 Kibana 。Logstash 通過輸入外掛程式從多種資料源（比如日志檔案、標準輸入 Stdin 等）獲取資料，再經過濾外掛程式加工資料，然後經 Elasticsearch 輸出外掛程式輸出到 Elasticsearch，通過 Kibana 展示。 把一個 Logstash 資料搜集節點擴展到多個，分布于多台機器，將解析好的資料傳送到 Elasticsearch server 進行存儲，最後在 Kibana 查詢、生成日志報表等。 原文網址：https://ifun01.com/BHBLFYZ.html 這種結構因為需要在各個伺服器上部署 Logstash，而它比較消耗 CPU 和內存資源，所以比較適合計算資源豐富的伺服器，否則容易造成伺服器性能下降，甚至可能導致無法正常工作。 原文網址：https://ifun01.com/BHBLFYZ.html filebeat 架構filebeat.yml中需設定日誌檔案的路徑，每個日誌檔案(LOG)，Filebeat啟動harvester(收割機)。每個harvester讀取新的內容一個日誌檔案，新的日誌資料傳送到spooler（後台處理程式），它匯集的事件和聚合資料傳送到你已經配置了Filebeat輸出。 原文網址 1.https://ifun01.com/BHBLFYZ.html 2.https://ifun01.com/8JODF4K.html","categories":[],"tags":[]},{"title":"Kubernetes","slug":"Kubernetes","date":"2018-03-27T09:02:07.000Z","updated":"2018-04-05T17:59:30.788Z","comments":true,"path":"2018/03/27/Kubernetes/","link":"","permalink":"https://www.yahuihu.info/2018/03/27/Kubernetes/","excerpt":"","text":"Kubernetes 是什麼Kubernetes(通常稱為K8s)是 Google 團隊開發的開源項目，它的目標是管理跨多個主机的容器平台，它建置在docker技術之上，用於自動部署、隨時擴展或收縮容器和管理容器化（containerized）應用程式的開源系統。簡言之，以更高效的方式自動化跨群集的應用程序容器的分發和調度。 主服務器(master)管理集群，節點(nodes)用於管理正在運行的應用程序。 在 kubernetes 的設定中，最基本的管理单位是pod。pod是一個或多個容器的組合，容器才是真正的執行個體。Pod中的每個容器都共享網路，包括IP地址和網路端口 K8S屬分布式系統，主要元件有：一、Master – 主服務器(master)管理集群。包含以下元件： 1.API Server：是整個系统的對外接口，提供給外部使用者和內部元件呼叫。 2.scheduler：負責各種排程作業、對資源進行調度，分配某個pod 到某個節點node上。 3.controller：負責執行各種控制。二、Node – 執行k8s的實體或虛擬的主機，並運行了許多容器。包含以下元件： 1.kubelet：負責Kubernetes Master和Node之間的通信的過程; 它管理機器上運行的Pod和容器。 2.kubernetes proxy：Proxy是為了解決外部網絡能夠訪問跨機器集群中容器提供的應用服務。 3.docker：管理pod、檢查容器是否正常運行、監控所有節點的資源使用狀況，是Pod中使用的最常見的容器運行 K8S 架構 這些節點使用主機公開的Kubernetes API與主機進行通信。 Kubernetes中所有的配置都是通过API对象的spec去设置的kubernates是使用etcd做為系統的設定儲存中心、重要資料都是持久化在etcd中的。kubectl是和Kubernetes API交互的命令行程序kubectl是用於針對Kubernetes群集運行命令的命令行界面 Kubernetes集群内部存在三個IP，分别是：Node IP：主機的IP地址Pod IP：使用网络插件创建的IP（如flannel），使跨主机的Pod可以互通Cluster IP：虚拟IP，通过iptables规则访问服务 K8S建置教學 (以三台環境建置為例)環境需3台。一台當master，二台當node 「master、node」登入後切換至最高權限 sudo su執行apt-get update執行apt-get upgrade -y執行apt-get dist-upgrade -y安裝docker：apt-get install –y docker.iokubeadm 管理k8s套件，依照文件照操作，如下圖 apt-get update &amp;&amp; apt-get install -y apt-transport-https curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - cat &lt;/etc/apt/sources.list.d/kubernetes.listdeb http://apt.kubernetes.io/ kubernetes-xenial mainEOF apt-get update apt-get install -y kubelet kubeadm kubectl 「master、node」關閉SWAP，因為SWAP開著會無法安裝K8S執行swapoff –a 安裝完kubeadm之後進行初始化和架設網路，網路是使用fiannl來建置。「master」 kubeadm初始化文件 執行kubeadm init –pod-network-cidr=10.244.0.0/16 「master」kubeadm架設網路執行sysctl net.bridge.bridge-nf-call-iptables=1「master」建置資料夾、COYP檔案、修改權限執行mkdir -p $HOME/.kube執行sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config執行sudo chown $(id -u):$(id -g) $HOME/.kube/config執行完後會出現join node，綠框的金鑰複製下來。 「node」 join node，貼上金鑰讓node加入到master，即完成cluster 「master」真正分配網路 「master」檢查 DNS 狀態狀態執行kubectl get pods –namespace kube-system剛開始 dns 還是 pending 狀態，等過一段時間後就會是 running 狀態以上k8s建置完畢 測試cluster，以nginx為例建置nginx pods狀態，nginx的狀態要在running執行kubectl run nginx –image=nginx –replicas=2 –port=80查詢pods開始部署開服務使用的port查詢服務狀態 網頁測試 如需重建，整組刪掉後再進行kubectl init 参考文獻https://kubernetes.io/docs/setup/independent/install-kubeadm/https://jimmysong.io/kubernetes-handbook/concepts/concepts.htmlhttp://cizixs.com/2016/10/25/kubernetes-intro-kubelet https://jimmysong.io/kubernetes-handbook https://kubernetes.io/docs/tutorials/kubernetes-basics/explore-intro/ https://yeasy.gitbooks.io/docker_practice/content/kubernetes/concepts.html","categories":[],"tags":[{"name":"Kubernetes、K8S","slug":"Kubernetes、K8S","permalink":"https://www.yahuihu.info/tags/Kubernetes、K8S/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-03-19T18:01:16.926Z","updated":"2018-03-28T09:51:21.409Z","comments":true,"path":"2018/03/20/hello-world/","link":"","permalink":"https://www.yahuihu.info/2018/03/20/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}